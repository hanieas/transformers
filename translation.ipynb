{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858996d-58f3-40b3-9a68-a0adcff19a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96131f7-10c6-455f-981a-8c718a8dc097",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5776459e-6d57-40cd-9f5b-7c41ca9aa940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from transformers import AutoTokenizer, BertTokenizer\n",
    "import string\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7656dbe1-3413-49ab-b329-65ebb9426088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73ef2a-aa9c-465a-92c5-dea66a3c36d8",
   "metadata": {},
   "source": [
    "# Load Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f26c6dad-a149-4994-87be-8b36767177e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parsinlu_translation_fa_en (/Users/haniyeh/.cache/huggingface/datasets/persiannlp___parsinlu_translation_fa_en/parsinlu-repo/1.0.0/43e422c8c7004e6912c9da2ec24a7401fe1c292f477ab458b62624526a246b4a)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016491174697875977,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f5a989676a4e6c83d603a65067110c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'targets', 'category'],\n",
       "        num_rows: 1622280\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'targets', 'category'],\n",
       "        num_rows: 47744\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['source', 'targets', 'category'],\n",
       "        num_rows: 2137\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"persiannlp/parsinlu_translation_fa_en\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93e2399a-038c-4771-94d0-7bfad41e0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(dataset['train'], columns = ['source','targets'])\n",
    "df_test = pd.DataFrame(dataset['test'], columns = ['source','targets'])\n",
    "df_val = pd.DataFrame(dataset['validation'], columns = ['source', 'targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b04d8d5-bf70-4c91-a1e7-bbdc6adf6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['target'] = df_train['targets'].map(lambda x: x[0])\n",
    "df_test['target'] = df_train['targets'].map(lambda x: x[0])\n",
    "df_val['target'] = df_train['targets'].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "741b23eb-64c2-4ece-ab69-ba381aabeb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>targets</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بلاگر مصری عبدل منعم محمود (عربی) پس از آزاد ش...</td>\n",
       "      <td>[Due Thank You note by Egyptian blogger Abdel ...</td>\n",
       "      <td>Due Thank You note by Egyptian blogger Abdel M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>وی از تمامی بلاگرها، سازمان‌ها و افرادی که از ...</td>\n",
       "      <td>[He thanked all fellow bloggers and organizati...</td>\n",
       "      <td>He thanked all fellow bloggers and organizatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وی همچنین از دریافت تعداد بسیار زیادی پیام تبر...</td>\n",
       "      <td>[He was extremely surprised and happy to recei...</td>\n",
       "      <td>He was extremely surprised and happy to receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>وی گفت در ابتدا قصد داشت درباره تجربه‌اش در زن...</td>\n",
       "      <td>[He had the intention to write about his last ...</td>\n",
       "      <td>He had the intention to write about his last e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وی در پایان نوشته‌اش می‌نویسد آزادی واقعا بها ...</td>\n",
       "      <td>[He concludes his post saying that freedom is ...</td>\n",
       "      <td>He concludes his post saying that freedom is t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  بلاگر مصری عبدل منعم محمود (عربی) پس از آزاد ش...   \n",
       "1  وی از تمامی بلاگرها، سازمان‌ها و افرادی که از ...   \n",
       "2  وی همچنین از دریافت تعداد بسیار زیادی پیام تبر...   \n",
       "3  وی گفت در ابتدا قصد داشت درباره تجربه‌اش در زن...   \n",
       "4  وی در پایان نوشته‌اش می‌نویسد آزادی واقعا بها ...   \n",
       "\n",
       "                                             targets  \\\n",
       "0  [Due Thank You note by Egyptian blogger Abdel ...   \n",
       "1  [He thanked all fellow bloggers and organizati...   \n",
       "2  [He was extremely surprised and happy to recei...   \n",
       "3  [He had the intention to write about his last ...   \n",
       "4  [He concludes his post saying that freedom is ...   \n",
       "\n",
       "                                              target  \n",
       "0  Due Thank You note by Egyptian blogger Abdel M...  \n",
       "1  He thanked all fellow bloggers and organizatio...  \n",
       "2  He was extremely surprised and happy to receiv...  \n",
       "3  He had the intention to write about his last e...  \n",
       "4  He concludes his post saying that freedom is t...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9850e-fe82-4b8a-a142-25f4626d691d",
   "metadata": {},
   "source": [
    "# Pre Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d98bae9-7007-4bf9-92ed-fe7c0e2032e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    punctuationFree=\"\".join([i for i in s if i not in string.punctuation])\n",
    "    return punctuationFree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55d24e36-b853-44dd-a2cc-826a40b51b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_persian_string(s):\n",
    "    punctuationFree = remove_punctuation(s)\n",
    "    return punctuationFree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f9ddda6-a1ec-4fc6-93ce-8df6c55e1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_english_string(s):\n",
    "    punctuationFree = remove_punctuation(s)\n",
    "    return punctuationFree.lower().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b7d05c-b09e-455d-a607-df68df907a9f",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21ba5ac6-c224-412c-ac46-2a1769890f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_model = \"HooshvareLab/bert-fa-base-uncased\"\n",
    "fa_tokenizer = BertTokenizer.from_pretrained(fa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55f50157-d960-40d5-83d2-e7dcd79660d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model = \"bert-base-uncased\"\n",
    "en_tokenizer = BertTokenizer.from_pretrained(en_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fc8af15-7e12-49cf-b761-1568f46a8624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n",
      "[1, 4, 0, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "FA_SPACIAL_TOKENS = fa_tokenizer.all_special_tokens\n",
    "FA_SPACIAL_TOKENS_IDS = fa_tokenizer.all_special_ids\n",
    "\n",
    "print(FA_SPACIAL_TOKENS)\n",
    "print(FA_SPACIAL_TOKENS_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5a3fe05-76f1-4b28-ae10-785fe6567f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n",
      "[100, 102, 0, 101, 103]\n"
     ]
    }
   ],
   "source": [
    "EN_SPACIAL_TOKENS = en_tokenizer.all_special_tokens\n",
    "EN_SPACIAL_TOKENS_IDS = en_tokenizer.all_special_ids\n",
    "\n",
    "print(EN_SPACIAL_TOKENS)\n",
    "print(EN_SPACIAL_TOKENS_IDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020d6050-a46a-4e10-a746-ca86634a2a0e",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd57c6bb-8ee1-4e34-9046-50805dc43a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(df):\n",
    "    data = []\n",
    "    for index, row in df.iterrows():\n",
    "        source = preprocess_persian_string(row['source'])\n",
    "        target = preprocess_english_string(row['target'])\n",
    "\n",
    "        fa_tensor_ = torch.tensor(fa_tokenizer(source).input_ids)\n",
    "        en_tensor_ = torch.tensor(en_tokenizer(target).input_ids)\n",
    "        data.append((fa_tensor_, en_tensor_))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffa277c6-62d1-4a0f-a4ad-2284b4f2a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = generate_data(df_train)\n",
    "test_data = generate_data(df_test)\n",
    "val_data = generate_data(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89c9e1ae-dd01-4b68-81e5-252c574ca354",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_data)\n",
    "train.to_csv('train.csv', index=False, header=False)\n",
    "\n",
    "val = pd.DataFrame(val_data)\n",
    "val.to_csv('val.csv', index=False, header=False)\n",
    "\n",
    "test = pd.DataFrame(test_data)\n",
    "test.to_csv('val.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6227086d-02c2-490d-a006-ea78a87545cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    2, 80928, 11391, 45770,  6625,  2015,  5931,  5279,  2965,  2791,\n",
       "          3912, 20633,  2791,  5511, 13477,  3455,  5071,  2847,  2803,  1064,\n",
       "          2842,  3912,  6794,  1078,  5279,  3229,  2830,     4]),\n",
       " tensor([  101,  2349,  4067,  2017,  3602,  2011,  6811, 28205, 19935,  2884,\n",
       "         12256,  6633, 27278,  2206,  2010,  2713,  2013,  3827,  2002,  2626,\n",
       "          2010,  2034,  9927,  4159,  1523,  9617, 20912, 18663,  2078,  1529,\n",
       "          1045,  2572,  2489,  1524,   102]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0810bbcb-fd9b-4301-8f01-d085c63c0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FA_TRAIN_VOCAB_SIZE = max([max(data[0]) for data in train_data])\n",
    "FA_VALIDATION_VOCAB_SIZE = max([max(data[0]) for data in val_data])\n",
    "FA_TEST_VOCAB_SIZE = max([max(data[0]) for data in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1926ea4c-8b04-4363-8684-5858f81559b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_TRAIN_VOCAB_SIZE = max([max(data[1]) for data in train_data])\n",
    "EN_VALIDATION_VOCAB_SIZE = max([max(data[1]) for data in val_data])\n",
    "EN_TEST_VOCAB_SIZE = max([max(data[1]) for data in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee8ef7c3-b72f-47f3-ac63-94cdfeb6c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FA_TRAIN_MAX_LEN = max([len(data[0]) for data in train_data])\n",
    "FA_VALIDATION_MAX_LEN = max([len(data[0]) for data in val_data])\n",
    "FA_TEST_MAX_LEN = max([len(data[0]) for data in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b93f7757-2a87-47f3-9812-7a8bd2bf62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_TRAIN_MAX_LEN = max([len(data[1]) for data in train_data])\n",
    "EN_VALIDATION_MAX_LEN = max([len(data[1]) for data in val_data])\n",
    "EN_TEST_MAX_LEN = max([len(data[1]) for data in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecf393e7-ce29-4bca-91a5-12877e175c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_MAX_LEN = max([FA_TRAIN_MAX_LEN,FA_VALIDATION_MAX_LEN,FA_TEST_MAX_LEN])\n",
    "TARGET_MAX_LEN = max([EN_TRAIN_MAX_LEN,EN_VALIDATION_MAX_LEN,EN_TEST_MAX_LEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0cf38c5-a522-4c5b-aa63-9ac74eb6a5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25a37e6c-8546-4140-9cc6-658f9e3a22a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    2, 80928, 11391, 45770,  6625,  2015,  5931,  5279,  2965,  2791,\n",
       "          3912, 20633,  2791,  5511, 13477,  3455,  5071,  2847,  2803,  1064,\n",
       "          2842,  3912,  6794,  1078,  5279,  3229,  2830,     4]),\n",
       " tensor([  101,  2349,  4067,  2017,  3602,  2011,  6811, 28205, 19935,  2884,\n",
       "         12256,  6633, 27278,  2206,  2010,  2713,  2013,  3827,  2002,  2626,\n",
       "          2010,  2034,  9927,  4159,  1523,  9617, 20912, 18663,  2078,  1529,\n",
       "          1045,  2572,  2489,  1524,   102]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c425b167-d9ba-4262-93a4-7e2bd4789be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "\n",
    "    data = []\n",
    "    for idx, (fa, en) in enumerate(data_batch):\n",
    "        if len(fa) < TARGET_MAX_LEN:\n",
    "            padding_tensor =  torch.zeros(TARGET_MAX_LEN - len(fa),dtype=int)\n",
    "            padding_tensor[:] = FA_SPACIAL_TOKENS_IDS[2]\n",
    "            fa = torch.cat((fa,padding_tensor), dim=0) \n",
    "        \n",
    "        if len(en) < TARGET_MAX_LEN:\n",
    "            padding_tensor =  torch.zeros(TARGET_MAX_LEN - len(en),dtype=int)\n",
    "            padding_tensor[:] = EN_SPACIAL_TOKENS_IDS[2]\n",
    "            en = torch.cat((en,padding_tensor), dim=0) \n",
    "        data.append( (fa,en) )\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5bc4c9a-96be-42fc-95f5-bfd2ea37e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = generate_batch(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83a9705a-da91-4808-9dd1-6e990cead2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_padded = generate_batch(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d4b2de1-ce46-41ec-8317-16caca333289",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded = generate_batch(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "052c4893-a6f4-46a0-a6a6-eac4390a9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_iter = DataLoader(train_padded, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_iter = DataLoader(val_padded, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_iter = DataLoader(test_padded, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad34eea-29c8-45a8-ba2d-6649aba099d9",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97103549-5b54-4705-8f53-dc4daf8910ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_VOCAB_SIZE = int(max([FA_TEST_VOCAB_SIZE, FA_TRAIN_VOCAB_SIZE, FA_VALIDATION_VOCAB_SIZE]))\n",
    "TARGET_VOCAB_SIZE = int(max([EN_TEST_VOCAB_SIZE, EN_TRAIN_VOCAB_SIZE, EN_VALIDATION_VOCAB_SIZE]))\n",
    "NUM_LAYER = 6\n",
    "# BATCH_SIZE = 32\n",
    "EMBED_DIMENSION = 512\n",
    "NUMBER_HEADS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0f7e4406-854f-4c1a-985f-4de600d068fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12]) torch.Size([32, 12])\n",
      "torch.Size([32, 12])\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/4t256kf1739f02pn7ldh71lw0000gn/T/ipykernel_74043/531710156.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.softmax(self.fc_layer(x))\n"
     ]
    }
   ],
   "source": [
    "%run transformer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c5507a05-73b9-4e01-86ff-e601960bc633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab_size, target_vocab_size, embed_dim, seq_len, num_layers, expansion_factor=4, n_heads=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.transformer = Transformer(embed_dim,src_vocab_size,target_vocab_size,seq_len,num_layers, expansion_factor, n_heads)\n",
    "        self.output = nn.Linear(embed_dim, target_vocab_size)\n",
    "\n",
    "    def forward(self,src, tgt):\n",
    "        print(\"tgt\",tgt.shape)\n",
    "        output = self.transformer(src, tgt)\n",
    "        \n",
    "        return self.output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83204f4a-8f1b-4b6d-9e5c-19cb2d3381f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer(model, iterator, optimizer, loss_fn, device, clip=None):\n",
    "    model.train()\n",
    "        \n",
    "    epoch_loss = 0\n",
    "    with tqdm(total=len(iterator), leave=False) as t:\n",
    "        for i, (src, tgt) in enumerate(iterator):\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "           \n",
    "            \n",
    "            # Create tgt_inp and tgt_out (which is tgt_inp but shifted by 1)\n",
    "            tgt_inp, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "            print(\"tgt_inp\", tgt_inp.shape)\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "            output = model(src=src, tgt=tgt_inp)\n",
    "            \n",
    "            loss = loss_fn(output.view(-1, output.shape[2]),\n",
    "                           tgt_out.view(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # if clip is not None:\n",
    "            #     nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            avg_loss = epoch_loss / (i+1)\n",
    "            t.set_postfix(loss='{:05.3f}'.format(avg_loss),\n",
    "                          ppl='{:05.3f}'.format(np.exp(avg_loss)))\n",
    "            t.update()\n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1176714a-905d-4b66-a0db-6478bdfa4e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transformer(model, iterator, loss_fn, device):\n",
    "    model.eval()\n",
    "        \n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(iterator), leave=False) as t:\n",
    "            for i, (src, tgt) in enumerate(iterator):\n",
    "                src = src.to(device)\n",
    "                tgt = tgt.to(device)\n",
    "                \n",
    "                # Create tgt_inp and tgt_out (which is tgt_inp but shifted by 1)\n",
    "                tgt_inp, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "\n",
    "                output = model(src=src, tgt=tgt_inp)\n",
    "                \n",
    "                loss = loss_fn(output.view(-1, output.shape[2]),\n",
    "                               tgt_out.view(-1))\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                avg_loss = epoch_loss / (i+1)\n",
    "                t.set_postfix(loss='{:05.3f}'.format(avg_loss),\n",
    "                              ppl='{:05.3f}'.format(np.exp(avg_loss)))\n",
    "                t.update()\n",
    "    \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b0722af-280f-4cb0-a663-a63b79396b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model, return_int=False):\n",
    "    params = sum([torch.prod(torch.tensor(x.shape)).item() for x in model.parameters() if x.requires_grad])\n",
    "    if return_int:\n",
    "        return params\n",
    "    else:\n",
    "        print(\"There are {:,} trainable parameters in this model.\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4fc327bd-7ad2-48c6-bb98-22d05e97f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransformerModel(src_vocab_size=SOURCE_VOCAB_SIZE, target_vocab_size=TARGET_VOCAB_SIZE, embed_dim=256, seq_len=TARGET_MAX_LEN, num_layers=2, expansion_factor=4, n_heads=8)\n",
    "\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3258c0d8-08a2-47de-a425-69af1766fc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 52,588,914 trainable parameters in this model.\n"
     ]
    }
   ],
   "source": [
    "count_params(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "56d90cfc-ab57-4c2f-9177-4292fe4e30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_optim = torch.optim.AdamW(transformer.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c292882e-7e48-4d4b-94f2-41e507e92438",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = FA_SPACIAL_TOKENS_IDS[2]\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "affa25c1-5fdf-47b6-b5e8-6660160a7fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03363204002380371,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Epoch",
       "rate": null,
       "total": 50,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7ae2880057414f80683f804b3bc888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012474775314331055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 101393,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbea32b1e50442a8be53312b4502e027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tgt_inp torch.Size([16, 350])\n",
      "tgt torch.Size([16, 350])\n",
      "torch.Size([16, 351])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (350) must match the size of tensor b (351) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:12\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [81]\u001b[0m, in \u001b[0;36mtrain_transformer\u001b[0;34m(model, iterator, optimizer, loss_fn, device, clip)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtgt_inp\u001b[39m\u001b[38;5;124m\"\u001b[39m, tgt_inp\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_inp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]),\n\u001b[1;32m     19\u001b[0m                tgt_out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [80]\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,src, tgt):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtgt\u001b[39m\u001b[38;5;124m\"\u001b[39m,tgt\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 11\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(output)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/var/folders/pb/4t256kf1739f02pn7ldh71lw0000gn/T/ipykernel_74043/2953077760.py:35\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m     32\u001b[0m enc_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(src\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 35\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/var/folders/pb/4t256kf1739f02pn7ldh71lw0000gn/T/ipykernel_74043/531710156.py:40\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, x, encoder_out, mask)\u001b[0m\n\u001b[1;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 40\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_layer(x))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/var/folders/pb/4t256kf1739f02pn7ldh71lw0000gn/T/ipykernel_74043/1113616133.py:32\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, key, query, x, mask)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, query, x, mask):\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m       key: key vector\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     attention_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhere\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm( attention_out \u001b[38;5;241m+\u001b[39m x ) )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/var/folders/pb/4t256kf1739f02pn7ldh71lw0000gn/T/ipykernel_74043/3111755827.py:31\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# print(\"query shape in multihead attention\", query.shape)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m query, key, value \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     27\u001b[0m     lin(x)\u001b[38;5;241m.\u001b[39mview(n_batches, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_head_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lin, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinears,(query, key, value))\n\u001b[1;32m     29\u001b[0m ]\n\u001b[0;32m---> 31\u001b[0m x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn \u001b[38;5;241m=\u001b[39m \u001b[43mattention_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     34\u001b[0m     x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;241m.\u001b[39mview(n_batches, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_head_dim)\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinears[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](x)\n",
      "File \u001b[0;32m/var/folders/pb/4t256kf1739f02pn7ldh71lw0000gn/T/ipykernel_74043/1151487986.py:12\u001b[0m, in \u001b[0;36mattention_fn\u001b[0;34m(query, key, value, mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(query, key\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(single_head_dim)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1e9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m p_attn \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmatmul(p_attn, value), p_attn\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (350) must match the size of tensor b (351) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_EPOCHS = 50\n",
    "CLIP = 16 # clipping value, or None to prevent gradient clipping\n",
    "EARLY_STOPPING_EPOCHS = 5\n",
    "SAVE_DIR = ''\n",
    "import os\n",
    "    \n",
    "model_path = os.path.join(SAVE_DIR, 'transformer_en_fr.pt')\n",
    "transformer_metrics = {}\n",
    "best_valid_loss = float(\"inf\")\n",
    "early_stopping_count = 0\n",
    "for epoch in tqdm(range(N_EPOCHS), desc=\"Epoch\"):\n",
    "    train_loss = train_transformer(transformer, train_iter, xf_optim, loss_fn, device, clip=CLIP)\n",
    "    valid_loss = evaluate_transformer(transformer, valid_iter, loss_fn, device)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        tqdm.write(f\"Checkpointing at epoch {epoch + 1}\")\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(transformer.state_dict(), model_path)\n",
    "        early_stopping_count = 0\n",
    "    elif epoch > EARLY_STOPPING_EPOCHS:\n",
    "        early_stopping_count += 1\n",
    "    \n",
    "    transformer_metrics[epoch+1] = dict(\n",
    "        train_loss = train_loss,\n",
    "        train_ppl = np.exp(train_loss),\n",
    "        valid_loss = valid_loss,\n",
    "        valid_ppl = np.exp(valid_loss)\n",
    "    )\n",
    "    \n",
    "    if early_stopping_count == EARLY_STOPPING_EPOCHS:\n",
    "        tqdm.write(f\"Early stopping triggered in epoch {epoch + 1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c1e0c1-8d38-470c-974b-b2eb285949e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f892c-7c71-4901-8a12-6bc2c316fd79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
