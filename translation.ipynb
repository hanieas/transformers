{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858996d-58f3-40b3-9a68-a0adcff19a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96131f7-10c6-455f-981a-8c718a8dc097",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5776459e-6d57-40cd-9f5b-7c41ca9aa940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from transformers import AutoTokenizer, BertTokenizer\n",
    "import string\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7656dbe1-3413-49ab-b329-65ebb9426088",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73ef2a-aa9c-465a-92c5-dea66a3c36d8",
   "metadata": {},
   "source": [
    "# Load Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c6dad-a149-4994-87be-8b36767177e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"persiannlp/parsinlu_translation_fa_en\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e2399a-038c-4771-94d0-7bfad41e0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(dataset['train'], columns = ['source','targets'])\n",
    "df_test = pd.DataFrame(dataset['test'], columns = ['source','targets'])\n",
    "df_val = pd.DataFrame(dataset['validation'], columns = ['source', 'targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b04d8d5-bf70-4c91-a1e7-bbdc6adf6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['target'] = df_train['targets'].map(lambda x: x[0])\n",
    "df_test['target'] = df_train['targets'].map(lambda x: x[0])\n",
    "df_val['target'] = df_train['targets'].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b23eb-64c2-4ece-ab69-ba381aabeb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9850e-fe82-4b8a-a142-25f4626d691d",
   "metadata": {},
   "source": [
    "# Pre Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d98bae9-7007-4bf9-92ed-fe7c0e2032e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    punctuationFree=\"\".join([i for i in s if i not in string.punctuation])\n",
    "    return punctuationFree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d24e36-b853-44dd-a2cc-826a40b51b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_persian_string(s):\n",
    "    punctuationFree = remove_punctuation(s)\n",
    "    return punctuationFree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ddda6-a1ec-4fc6-93ce-8df6c55e1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_english_string(s):\n",
    "    punctuationFree = remove_punctuation(s)\n",
    "    return punctuationFree.lower().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b7d05c-b09e-455d-a607-df68df907a9f",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba5ac6-c224-412c-ac46-2a1769890f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_model = \"HooshvareLab/bert-fa-base-uncased\"\n",
    "fa_tokenizer = BertTokenizer.from_pretrained(fa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f50157-d960-40d5-83d2-e7dcd79660d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model = \"bert-base-uncased\"\n",
    "en_tokenizer = BertTokenizer.from_pretrained(en_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc8af15-7e12-49cf-b761-1568f46a8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "FA_SPACIAL_TOKENS = fa_tokenizer.all_special_tokens\n",
    "FA_SPACIAL_TOKENS_IDS = fa_tokenizer.all_special_ids\n",
    "\n",
    "print(FA_SPACIAL_TOKENS)\n",
    "print(FA_SPACIAL_TOKENS_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3fe05-76f1-4b28-ae10-785fe6567f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_SPACIAL_TOKENS = en_tokenizer.all_special_tokens\n",
    "EN_SPACIAL_TOKENS_IDS = en_tokenizer.all_special_ids\n",
    "\n",
    "print(EN_SPACIAL_TOKENS)\n",
    "print(EN_SPACIAL_TOKENS_IDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020d6050-a46a-4e10-a746-ca86634a2a0e",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57c6bb-8ee1-4e34-9046-50805dc43a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(df):\n",
    "    data = []\n",
    "    for index, row in df.iterrows():\n",
    "        source = preprocess_persian_string(row['source'])\n",
    "        target = preprocess_english_string(row['target'])\n",
    "\n",
    "        fa_tensor_ = torch.tensor(fa_tokenizer(source).input_ids)\n",
    "        en_tensor_ = torch.tensor(en_tokenizer(target).input_ids)\n",
    "        data.append((fa_tensor_, en_tensor_))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa277c6-62d1-4a0f-a4ad-2284b4f2a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = generate_data(df_train)\n",
    "test_data = generate_data(df_test)\n",
    "val_data = generate_data(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c9e1ae-dd01-4b68-81e5-252c574ca354",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_data)\n",
    "train.to_csv('train.csv', index=False, header=False)\n",
    "\n",
    "val = pd.DataFrame(val_data)\n",
    "val.to_csv('val.csv', index=False, header=False)\n",
    "\n",
    "test = pd.DataFrame(test_data)\n",
    "test.to_csv('val.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227086d-02c2-490d-a006-ea78a87545cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810bbcb-fd9b-4301-8f01-d085c63c0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FA_TRAIN_VOCAB_SIZE = max([max(data[0]) for data in train_data])\n",
    "FA_VALIDATION_VOCAB_SIZE = max([max(data[0]) for data in val_data])\n",
    "FA_TEST_VOCAB_SIZE = max([max(data[0]) for data in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926ea4c-8b04-4363-8684-5858f81559b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_TRAIN_VOCAB_SIZE = max([max(data[1]) for data in train_data])\n",
    "EN_VALIDATION_VOCAB_SIZE = max([max(data[1]) for data in val_data])\n",
    "EN_TEST_VOCAB_SIZE = max([max(data[1]) for data in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ef7c3-b72f-47f3-ac63-94cdfeb6c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FA_TRAIN_MAX_LEN = max([len(data[0]) for data in train_data])\n",
    "FA_VALIDATION_MAX_LEN = max([len(data[0]) for data in val_data])\n",
    "FA_TEST_MAX_LEN = max([len(data[0]) for data in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f7757-2a87-47f3-9812-7a8bd2bf62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_TRAIN_MAX_LEN = max([len(data[1]) for data in train_data])\n",
    "EN_VALIDATION_MAX_LEN = max([len(data[1]) for data in val_data])\n",
    "EN_TEST_MAX_LEN = max([len(data[1]) for data in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf393e7-ce29-4bca-91a5-12877e175c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_MAX_LEN = max([FA_TRAIN_MAX_LEN,FA_VALIDATION_MAX_LEN,FA_TEST_MAX_LEN])\n",
    "TARGET_MAX_LEN = max([EN_TRAIN_MAX_LEN,EN_VALIDATION_MAX_LEN,EN_TEST_MAX_LEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf38c5-a522-4c5b-aa63-9ac74eb6a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a37e6c-8546-4140-9cc6-658f9e3a22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425b167-d9ba-4262-93a4-7e2bd4789be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "\n",
    "    data = []\n",
    "    for idx, (fa, en) in enumerate(data_batch):\n",
    "        if len(fa) < TARGET_MAX_LEN:\n",
    "            padding_tensor =  torch.zeros(TARGET_MAX_LEN - len(fa),dtype=int)\n",
    "            padding_tensor[:] = FA_SPACIAL_TOKENS_IDS[2]\n",
    "            fa = torch.cat((fa,padding_tensor), dim=0) \n",
    "        \n",
    "        if len(en) < TARGET_MAX_LEN:\n",
    "            padding_tensor =  torch.zeros(TARGET_MAX_LEN - len(en),dtype=int)\n",
    "            padding_tensor[:] = EN_SPACIAL_TOKENS_IDS[2]\n",
    "            en = torch.cat((en,padding_tensor), dim=0) \n",
    "        data.append( (fa,en) )\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc4c9a-96be-42fc-95f5-bfd2ea37e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = generate_batch(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9705a-da91-4808-9dd1-6e990cead2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_padded = generate_batch(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b2de1-ce46-41ec-8317-16caca333289",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded = generate_batch(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c4893-a6f4-46a0-a6a6-eac4390a9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_iter = DataLoader(train_padded, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_iter = DataLoader(val_padded, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_iter = DataLoader(test_padded, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad34eea-29c8-45a8-ba2d-6649aba099d9",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97103549-5b54-4705-8f53-dc4daf8910ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_VOCAB_SIZE = int(max([FA_TEST_VOCAB_SIZE, FA_TRAIN_VOCAB_SIZE, FA_VALIDATION_VOCAB_SIZE]))\n",
    "TARGET_VOCAB_SIZE = int(max([EN_TEST_VOCAB_SIZE, EN_TRAIN_VOCAB_SIZE, EN_VALIDATION_VOCAB_SIZE]))\n",
    "NUM_LAYER = 6\n",
    "# BATCH_SIZE = 32\n",
    "EMBED_DIMENSION = 512\n",
    "NUMBER_HEADS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7e4406-854f-4c1a-985f-4de600d068fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run transformer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5507a05-73b9-4e01-86ff-e601960bc633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab_size, target_vocab_size, embed_dim, seq_len, num_layers, expansion_factor=4, n_heads=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.transformer = Transformer(embed_dim,src_vocab_size,target_vocab_size,seq_len,num_layers, expansion_factor, n_heads)\n",
    "        self.output = nn.Linear(embed_dim, target_vocab_size)\n",
    "\n",
    "    def forward(self,src, tgt):\n",
    "        print(\"tgt\",tgt.shape)\n",
    "        output = self.transformer(src, tgt)\n",
    "        \n",
    "        return self.output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83204f4a-8f1b-4b6d-9e5c-19cb2d3381f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer(model, iterator, optimizer, loss_fn, device, clip=None):\n",
    "    model.train()\n",
    "        \n",
    "    epoch_loss = 0\n",
    "    with tqdm(total=len(iterator), leave=False) as t:\n",
    "        for i, (src, tgt) in enumerate(iterator):\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "           \n",
    "            \n",
    "            # Create tgt_inp and tgt_out (which is tgt_inp but shifted by 1)\n",
    "            tgt_inp, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "            print(\"tgt_inp\", tgt_inp.shape)\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "            output = model(src=src, tgt=tgt_inp)\n",
    "            \n",
    "            loss = loss_fn(output.view(-1, output.shape[2]),\n",
    "                           tgt_out.view(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # if clip is not None:\n",
    "            #     nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            avg_loss = epoch_loss / (i+1)\n",
    "            t.set_postfix(loss='{:05.3f}'.format(avg_loss),\n",
    "                          ppl='{:05.3f}'.format(np.exp(avg_loss)))\n",
    "            t.update()\n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1176714a-905d-4b66-a0db-6478bdfa4e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transformer(model, iterator, loss_fn, device):\n",
    "    model.eval()\n",
    "        \n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(iterator), leave=False) as t:\n",
    "            for i, (src, tgt) in enumerate(iterator):\n",
    "                src = src.to(device)\n",
    "                tgt = tgt.to(device)\n",
    "                \n",
    "                # Create tgt_inp and tgt_out (which is tgt_inp but shifted by 1)\n",
    "                tgt_inp, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "\n",
    "                output = model(src=src, tgt=tgt_inp)\n",
    "                \n",
    "                loss = loss_fn(output.view(-1, output.shape[2]),\n",
    "                               tgt_out.view(-1))\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                avg_loss = epoch_loss / (i+1)\n",
    "                t.set_postfix(loss='{:05.3f}'.format(avg_loss),\n",
    "                              ppl='{:05.3f}'.format(np.exp(avg_loss)))\n",
    "                t.update()\n",
    "    \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0722af-280f-4cb0-a663-a63b79396b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model, return_int=False):\n",
    "    params = sum([torch.prod(torch.tensor(x.shape)).item() for x in model.parameters() if x.requires_grad])\n",
    "    if return_int:\n",
    "        return params\n",
    "    else:\n",
    "        print(\"There are {:,} trainable parameters in this model.\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc327bd-7ad2-48c6-bb98-22d05e97f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransformerModel(src_vocab_size=SOURCE_VOCAB_SIZE, target_vocab_size=TARGET_VOCAB_SIZE, embed_dim=256, seq_len=TARGET_MAX_LEN, num_layers=2, expansion_factor=4, n_heads=8)\n",
    "\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258c0d8-08a2-47de-a425-69af1766fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_params(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d90cfc-ab57-4c2f-9177-4292fe4e30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_optim = torch.optim.AdamW(transformer.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292882e-7e48-4d4b-94f2-41e507e92438",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = FA_SPACIAL_TOKENS_IDS[2]\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affa25c1-5fdf-47b6-b5e8-6660160a7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "N_EPOCHS = 50\n",
    "CLIP = 16 # clipping value, or None to prevent gradient clipping\n",
    "EARLY_STOPPING_EPOCHS = 5\n",
    "SAVE_DIR = ''\n",
    "import os\n",
    "    \n",
    "model_path = os.path.join(SAVE_DIR, 'transformer_en_fr.pt')\n",
    "transformer_metrics = {}\n",
    "best_valid_loss = float(\"inf\")\n",
    "early_stopping_count = 0\n",
    "for epoch in tqdm(range(N_EPOCHS), desc=\"Epoch\"):\n",
    "    train_loss = train_transformer(transformer, train_iter, xf_optim, loss_fn, device, clip=CLIP)\n",
    "    valid_loss = evaluate_transformer(transformer, valid_iter, loss_fn, device)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        tqdm.write(f\"Checkpointing at epoch {epoch + 1}\")\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(transformer.state_dict(), model_path)\n",
    "        early_stopping_count = 0\n",
    "    elif epoch > EARLY_STOPPING_EPOCHS:\n",
    "        early_stopping_count += 1\n",
    "    \n",
    "    transformer_metrics[epoch+1] = dict(\n",
    "        train_loss = train_loss,\n",
    "        train_ppl = np.exp(train_loss),\n",
    "        valid_loss = valid_loss,\n",
    "        valid_ppl = np.exp(valid_loss)\n",
    "    )\n",
    "    \n",
    "    if early_stopping_count == EARLY_STOPPING_EPOCHS:\n",
    "        tqdm.write(f\"Early stopping triggered in epoch {epoch + 1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c1e0c1-8d38-470c-974b-b2eb285949e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f892c-7c71-4901-8a12-6bc2c316fd79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
